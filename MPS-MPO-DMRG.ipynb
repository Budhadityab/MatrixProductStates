{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Threads;\n",
    "using Plots, LinearAlgebra, Distributions, Compose, LaTeXStrings, JLD2, Pkg, SparseArrays;\n",
    "using ITensors, ITensorMPS,InvertedIndices,Einsum, BenchmarkTools, KrylovKit, Arpack;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The first step is to learn how to write tensors, with the bond dimension(s) and real dimension(s). \n",
    "\n",
    "$\\quad$ We will denote bond dimensions by $D$, and physical dimensions by $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ We build a tensor by making an object that has $N$ indices, each index will carry a $D \\times D$ dimensional object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This is what a tensor will look like\"\"\"\n",
    "\n",
    "N = 5; #This is the total number of indices. This corresponds to the rank of the tensor\n",
    "D = 2; #This is the number of values that each index can take.\n",
    "tensor_size = ntuple(_ -> D, N); #This creates a set like (D,D,D,D) for N = 4\n",
    "tensor = fill(0.0, tensor_size...); #This creates a tensor of dimensions (D,D,D,D) for N = 4 and fills each of the element with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Product States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ Now we construct a $3-$ tensor, which is the building block of an MPS (of bond dimension $d$ and physical dimension $D$). \n",
    "\n",
    "$\\quad$ A general MPS can be constructed by a sequence of $3$ tensors, where \n",
    "\n",
    "$\\quad$ 1. The left-most tensor has dimensions $(1,d, D)$\n",
    " \n",
    "$\\quad$ 2. The right-most tensor has dimension $(D,d,1)$ and \n",
    "\n",
    "$\\quad$ 3. All those in between have dimensions $(D,d,D)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here we choose the bond dimension to be same across all bonds, for simplicity. It can be changed easily \"\"\"\n",
    "\n",
    "M = 10;         # Number of sites.\n",
    "d = 3;          # Physical dimension at each site.\n",
    "D = 20;         # Bond dimension.\n",
    "\n",
    "generic_mps = Any[];\n",
    "\n",
    "push!(generic_mps,rand(Normal(0,1),(1,d,D)));\n",
    "\n",
    "for i in 2:M-1\n",
    "\n",
    "    push!(generic_mps,rand(Normal(0,1),(D,d,D)));\n",
    "\n",
    "end\n",
    "\n",
    "push!(generic_mps,rand(Normal(0,1),(D,d,1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The next step is to turn a $3-$ tensor into a $2-$ tensor (matrix) by $\\textit{reshaping}$. We do this to eventually be able to perform SVD.\n",
    "\n",
    "$\\quad$ The goal of performing SVD is to turn the MPS into a left (or right) canonical form, thereby also normalizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor_reshape_fuse (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This general function reshapes a tensor according to the input provided by the user. \n",
    "\n",
    "    The inputs are the tensor, the rank of the tensor and the indices that need to be fused into one index.\n",
    "\n",
    "    In the even that fusions have to be done, then this function has to be used successively \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "function tensor_reshape_fuse(tensor_input,tensor_rank,tensor_indices_to_fuse;fused_location = 1)\n",
    "    temp_tensor = copy(tensor_input); # Create a copy of the tensor that is provided as input\n",
    "\n",
    "    initial_rank = tensor_rank; #This is the rank of the input tensor\n",
    "    final_rank = initial_rank - length(tensor_indices_to_fuse) + 1; # This is the final rank to be obtained after reshaping\n",
    "\n",
    "\n",
    "    dims2 = prod(size(temp_tensor)[i] for i in tensor_indices_to_fuse); # This is the dimension of the index obtained by\n",
    "                                                                        # fusing the indices that are provided as argument\n",
    "                                                                        # via \"tensor_indices_to fuse\"\n",
    "\n",
    "    res_tup = ntuple(_-> 0,final_rank);  # This is the tuple where the final shape will be stored.\n",
    "\n",
    "\n",
    "    res_tup = setindex(res_tup, dims2,fused_location); # \"fused_location\" defines the index (in the final tensor) to which the fused\n",
    "                                                       # index is ultimately mapped \n",
    "    \n",
    "    initial_indices = vec(1:1:tensor_rank); # This is the list of initial indices of the tensor\n",
    "    initial_indices_remain = Any[]; # This is the vector that stores the final set of indices (that are not fused)\n",
    "                                    # Note that the index numbering is the same as the original tensor.\n",
    "                                    # For example, if a tensor of has indices (i1,i2,i3,i4) and we want to fuse (i2,i3)\n",
    "                                    # then intial_indices_remain will store (i1,i2)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in 1:tensor_rank\n",
    "        if i in tensor_indices_to_fuse\n",
    "            nothing;\n",
    "        else \n",
    "            push!(initial_indices_remain,initial_indices[i])\n",
    "        end\n",
    "    end\n",
    "    push!(initial_indices_remain,-1);\n",
    "    initial_indices_remain = sort(initial_indices_remain);\n",
    "\n",
    "    initial_indices_remain[1], initial_indices_remain[fused_location] = initial_indices_remain[fused_location], initial_indices_remain[1]\n",
    "\n",
    "    # The following loop sets the tuple that stores the dimensions of the final tensor\n",
    "    # The dimensions of the fused indices are stored at fused_location\n",
    "    # For all the other locations, we just store the dimensions of the remaining indices of the\n",
    "    # original tensor.\n",
    "\n",
    "    tsize = size(temp_tensor);\n",
    "    for i in 1:final_rank\n",
    "        if initial_indices_remain[i]!=-1\n",
    "            res_tup = setindex(res_tup,tsize[initial_indices_remain[i]],i)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # The final (easiest) step is to reshape the tensor.\n",
    "\n",
    "    temp_tensor = reshape(temp_tensor,res_tup)\n",
    "\n",
    "    return temp_tensor\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor_reshape_split (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This function is built to take a particular tensor index, and split it into multiple tensor indices of specified dimensions. \n",
    "    Again, if multiple indices have to be split then this has to be applied multiple times.\n",
    "\"\"\"\n",
    "\n",
    "function tensor_reshape_split(tensor_input,index_to_split,pos_indices,dimensions_of_output_indices)\n",
    "    temp_tensor = copy(tensor_input); # Create a copy of the tensor that is provided as input\n",
    "\n",
    "    dims_in = size(temp_tensor)[index_to_split]; # This is the dimensions of the input tensor index that has to be split\n",
    "\n",
    "    dims_out = dimensions_of_output_indices; # This is the dimensions of the output indices\n",
    "\n",
    "    initial_indices = collect(size(temp_tensor))[Not(index_to_split)]; #The dimensions of the initial tensor, except the index which has to be splot\n",
    "\n",
    "    initial_rank = length(size(temp_tensor)); #The rank of the initial tensor\n",
    "\n",
    "    final_rank = length(size(temp_tensor)) - 1 + length(pos_indices); #The rank of the final tensor\n",
    "\n",
    "    res_tup = ntuple(_->0, final_rank) # This tuple stores the dimensions of the final tensor\n",
    "\n",
    "    # The tuple is then modified by storing the dimensions of the split index in the locations specified in \"pos_indices\", and the remaining\n",
    "    # ones in the remaining locations.\n",
    "\n",
    "    j1 = 1;\n",
    "    j2 = 1;\n",
    "    for i in 1:final_rank\n",
    "        if i in pos_indices\n",
    "            res_tup = setindex(res_tup,dims_out[j1],i)\n",
    "            j1 += 1;\n",
    "        else\n",
    "            res_tup = setindex(res_tup,initial_indices[j2],i)\n",
    "            j2 += 1;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # The final (easiest) step is to reshape the tensor.\n",
    "\n",
    "    temp_tensor = reshape(temp_tensor,res_tup)\n",
    "\n",
    "    return temp_tensor\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The next step is to evaluate the left and right canonical forms of the MPS, by using SVD\n",
    "\n",
    "$\\quad$ For this, we shall use $\\textit{reshaping}$ procedure, but without the more general functions because they are not required for these specific cases.\n",
    "\n",
    "$\\quad$ The steps are as follows:\n",
    "\n",
    "$\\quad$ 1. First, reshape every $3-$ tensor in the MPS into a $2-$ tensor (i.e. matrix) by fusing the left and central leg.\n",
    "\n",
    "$\\quad$ 2. Then perform an SVD to break the matrix into $U$, $S$ and $V^\\dagger$. Here $U$ actually corresponds to the fused legs.\n",
    "\n",
    "$\\quad$ 3. Then split $U$ into a $3-$ tensor. This $U$ now connects to $S V^\\dagger$, which then connect to the next tensor.\n",
    "\n",
    "$\\quad$ 4. Identify $U$ as the left canonical element of the MPS at that site. Then multiply $S V^\\dagger$ to the tensor at the next site (by using Einstein summation convention for tensor multiplication between a $2-$ tensor and a $3-$ tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_canonical (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    This function generates the left canonical form, and then makes sure that it is normalized.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function left_canonical(MPS_state)\n",
    "    mps_st = copy(MPS_state);\n",
    "\n",
    "    N = length(mps_st); # This is the number of lattice site indices that the MPS corresponds to.\n",
    "\n",
    "    for i in 1:N\n",
    "\n",
    "        T = mps_st[i]; # Picking the i th tensor\n",
    "\n",
    "        T_res = tensor_reshape_fuse(T,3,[1,2]); # Reshape the tensor into a matrix by fusing its' first and second indices\n",
    "\n",
    "        U, S, V = svd(T_res,full=false); # Perform the SVD to extract U, S and V\n",
    "\n",
    "        Vt = V'; # Store V transpose, since that is what we shall be using\n",
    "\n",
    "        mps_st[i] = tensor_reshape_split(U,1,[1,2],[size(T)[1],size(T)[2]]);\n",
    "\n",
    "        SV = Diagonal(S)*Vt;\n",
    "\n",
    "        if i < N - 1\n",
    "            mps_next = mps_st[i+1]\n",
    "            @einsum nsite_update[i,j,k] :=  SV[i,l]*mps_next[l,j,k];\n",
    "            mps_st[i + 1] = nsite_update;\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    return mps_st \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "right_canonical (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    This function generates the right canonical form, and then makes sure that it is normalized.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function right_canonical(MPS_state)\n",
    "    mps_st = copy(MPS_state);\n",
    "\n",
    "    N = length(mps_st); # This is the number of lattice site indices that the MPS corresponds to.\n",
    "\n",
    "    for i in N:-1:1\n",
    "        \n",
    "\n",
    "        T = mps_st[i]; # Picking the i th tensor\n",
    "\n",
    "        T_res = tensor_reshape_fuse(T,3,[2,3];fused_location=2); # Reshape the tensor into a matrix by fusing its' first and second indices\n",
    "\n",
    "        U, S, V = svd(T_res,full=false); # Perform the SVD to extract U, S and V \n",
    "\n",
    "        mps_st[i] = tensor_reshape_split(V',2,[2,3],[size(T)[2],size(T)[3]]); # Reshape V transpose to store it as the 3-tensor at that location\n",
    "\n",
    "        US = U*Diagonal(S); # Evaluate U*S as that has to combine with the previous tensor\n",
    "\n",
    "        if i > 1\n",
    "            mps_prev = mps_st[i-1]\n",
    "            @einsum nsite_update[i,j,k] :=  mps_prev[i,j,l]*US[l,k];\n",
    "            mps_st[i - 1] = nsite_update;\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    return mps_st \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ In this step, we verify whether the (left and right cannonical) MPS that we have generated is accurate or not.\n",
    "\n",
    "$\\quad$ A simple check is to see if all the tensors in the left (right) cannonical form become left (right) normalized.\n",
    "\n",
    "$\\quad$ The normalisation constraint is imposed by taking each tensor $M_{\\alpha \\beta \\gamma}$ and demanding that \n",
    "\n",
    "$\\quad$ $\\sum_{\\alpha, \\beta} M_{\\alpha \\beta \\gamma}^{\\dagger} M_{\\alpha \\beta \\gamma'} = \\delta_{\\gamma \\gamma'}$. Note that $M^{\\dagger}_{a b c} = M^{*}_{c b a}$. This is $\\textit{left normalization}$.\n",
    "\n",
    "$\\quad$ For $\\textit{right normalization}$ , we impose $\\sum M^{\\dagger}_{\\alpha \\beta \\gamma} M_{\\alpha' \\beta \\gamma} = \\delta_{\\alpha \\alpha'}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deficit = 1.609823385706477e-14"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Here we check the normalization condition on each tensor for the right canonical form of the MPS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "N = 10;\n",
    "\n",
    "mps_right_c = right_canonical(generic_mps)\n",
    "\n",
    "deficit = 0.0;\n",
    "for l in 1:N\n",
    "    mps_dag = permutedims(conj.(mps_right_c[l]),(3,2,1)) #right-top-left\n",
    "\n",
    "    B = mps_right_c[l];\n",
    "\n",
    "    @einsum MPSprod[i,m] := B[i,j,k]*mps_dag[k,j,m] #top-bottom\n",
    "\n",
    "    A = I + fill(0.0,size(MPSprod))\n",
    "    \n",
    "    deficit += maximum(abs.(MPSprod-A))\n",
    "end\n",
    "print(\"Deficit = \" ,deficit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deficit = 1.7430501486614958e-14"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Here we check the normalization condition on each tensor for the left canonical form of the MPS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "N = 10;\n",
    "\n",
    "mps_left_c = left_canonical(generic_mps)\n",
    "\n",
    "deficit = 0.0;\n",
    "for l in 1:N\n",
    "    mps_dag = permutedims(conj.(mps_left_c[l]),(3,2,1)) #right-top-left\n",
    "\n",
    "    B = mps_left_c[l];\n",
    "\n",
    "    @einsum MPSprod[i,m] := mps_dag[i,j,k]*B[k,j,m] #top-bottom\n",
    "\n",
    "    A = I + fill(0.0,size(MPSprod))\n",
    "    \n",
    "    deficit += maximum(abs.(MPSprod-A))\n",
    "end\n",
    "print(\"Deficit = \" ,deficit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mixed_canonical (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This function performs a left canonical transformation on the MPS and then follows it up with right canonical transformation. This should give the\n",
    "    most compact representation of the MPS with the least bond dimensions.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "function mixed_canonical(MPS_state)\n",
    "\n",
    "    mps_temp = MPS_state;\n",
    "\n",
    "    mps_left = left_canonical(mps_temp);\n",
    "\n",
    "    mps_mixed = right_canonical(mps_left);\n",
    "\n",
    "    return mps_mixed\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MPS operation : Closing the Zipper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ Here we describe the ``closing the zipper'' method that is used to efficiently compute norms and inner products. \n",
    "\n",
    "$\\quad$ The first part will deal with inner products of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rand_MPS (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    The first step is to write a function to generate a random MPS for ease of calculation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function rand_MPS(N,d,D; d1 = Normal(0,1))\n",
    "\n",
    "    generic_mps = Any[];\n",
    "\n",
    "    push!(generic_mps,rand(d1,(1,d,D)));\n",
    "\n",
    "    for i in 2:N-1\n",
    "\n",
    "        push!(generic_mps,rand(d1,(D,d,D)));\n",
    "\n",
    "    end\n",
    "\n",
    "    push!(generic_mps,rand(d1,(D,d,1)));\n",
    "\n",
    "    return generic_mps\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first discuss the process of closing the zipper for states:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ Let us consider that we have two states $\\ket{\\psi}$ and $\\ket{\\phi}$, which may have different bond dimensions. We evaluate $\\braket{\\phi\\vert\\psi}$\n",
    "\n",
    "$\\quad$ The basic operation ``closing the zipper'' is to contract $3$ indices, between the $n^{\\text{th}}$ tensor of the MPS of $\\ket{\\psi}$ (denoted by $A_{n}$) and that of $\\ket{\\phi}$ (denoted by $B^{\\dagger}_{n}$). \n",
    "\n",
    "$\\quad$ Two of the indices are connected to the $2-$ tensor that has stored the result of the process till $n - 1$ (this is $C_{n - 1}$), and the remaining contraction is between the physical index legs of $\\ket{\\psi}$ and $\\ket{\\psi}$, which have dimension $d$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_left (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function zip_left(Cn_minus_1, An, Bn)\n",
    "    \n",
    "    # We count the legs from left to right. Thus, the first index of Cn_minus_1 must have bond dimension same as An, and the second index should\n",
    "    # have bond dimension same as Bn\n",
    "\n",
    "    Cn1 = Cn_minus_1;\n",
    "\n",
    "    @einsum M1[i,j,l] := Bn[i,j,k]*Cn1[k,l]\n",
    "\n",
    "    @einsum M2[i,l] := M1[i,j,p]*An[p,j,l]\n",
    "\n",
    "    return M2\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ To test out this code, we take two random MPS states and try to determine what their inner product is. We use mixed canonical form to do this.\n",
    "\n",
    "$\\quad$ Turns out that this gives us a number, as expected (yay! it works!). Taking both states to be the same gives $1$, since mixed canonical forms are normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013436658350211662"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    \n",
    "    Testing Inner product via (left) closing the zipper method \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "N = 10;\n",
    "d = 2;\n",
    "D1 = 20;\n",
    "D2 = 10;\n",
    "\n",
    "M_norm = fill(1.0,(1,1));\n",
    "\n",
    "mps_1 = mixed_canonical(rand_MPS(N,d,D1));\n",
    "\n",
    "mps_2 = mixed_canonical(rand_MPS(N,d,D2));\n",
    "\n",
    "for p in 1:N\n",
    "\n",
    "    A_n = mps_1[p];\n",
    "\n",
    "    B_n = mps_2[p];\n",
    "\n",
    "    B_n_dag = permutedims(conj.(B_n),(3,2,1));\n",
    "\n",
    "    M_norm = zip_left(M_norm, A_n, B_n_dag);\n",
    "\n",
    "end\n",
    "\n",
    "print(M_norm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inner_product (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Here we write a function that takes two MPS states and gives their inner product\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function inner_product(mps_state_1, mps_state_2)\n",
    "\n",
    "    mps_1 = mps_state_2 # This is the ket state.\n",
    "\n",
    "    mps_2 = mps_state_1 # This is the bra state\n",
    "\n",
    "    M_norm = fill(1.0,(1,1)); # This is C_1, which is just a 1 x 1 matrix with entry 1.0\n",
    "\n",
    "    N = length(mps_state_1); # This is the number of indices, and these must be the same.\n",
    "\n",
    "    for p in 1:N\n",
    "\n",
    "        A_n = mps_1[p];\n",
    "    \n",
    "        B_n = mps_2[p];\n",
    "    \n",
    "        B_n_dag = permutedims(conj.(B_n),(3,2,1));\n",
    "    \n",
    "        M_norm = zip_left(M_norm, A_n, B_n_dag);\n",
    "    \n",
    "    end\n",
    "\n",
    "    return M_norm[1]\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State to MPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The final part of this discussion on MPS (before going to MPO and DMRG) is to write a full state in the Hilbert space in MPS notation\n",
    "\n",
    "$\\quad$ This will be the exact transformation, thus giving us unequal bond dimensions.\n",
    "\n",
    "$\\quad$ The first step is to write the state as an $d^N$ dimensional vector. We denote this by $\\Psi_{N}$.\n",
    "\n",
    "$\\quad$ The next step is to reshape $\\Psi_{N}$ into a $d \\times d^{N-1}$ matrix. \n",
    "\n",
    "$\\quad$ On this tensor, we perform SVD which gives a $d \\times d$ matrix $U$, which is then treated as the first local tensor of the MPS (call it $A_1$).\n",
    "\n",
    "$\\quad$ The remainder is the $d \\times d^{N-1}$ dimensional matrix.  Reshape this into a $d^2 \\times d^{N-2} \\equiv \\psi_1$ matrix, and then SVD it.\n",
    "\n",
    "$\\quad$ This gives a $d^2 \\times d^2$ matrix $U$, which is reshaped into $d \\times d \\times d^2$ tensor. This is the second tensor of the MPS, which we call $A_2$. \n",
    "\n",
    "$\\quad$ Note that the size of the left leg of $A_{n}$ is equal to the size of right leg of $A_{n - 1}$. The mid leg always has size $d$. This fixes the right leg as well.\n",
    "\n",
    "$\\quad$ $\\textcolor{blue}{The\\;\\;Key\\;\\;Point:}$ When reshaping $\\psi_{n} = S V^\\dagger$ (at the $n^\\text{th}$ step), the dimensions are determined as $(dim(S)*d, dim(\\psi_{n-1})/d)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_to_mps (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function state_to_mps(state_vector, N)\n",
    "\n",
    "    st_vec = state_vector # This is the d^N dimensional vector \n",
    "\n",
    "    d = Int(length(st_vec)^(1/N)); # The dimension at a single site\n",
    "\n",
    "    psi = reshape(st_vec,(d,d^(N-1))); # First step is to isolate the first index.\n",
    "\n",
    "    mps_state = Any[];\n",
    "\n",
    "    left_bond_dim = 1; # The bond dimension of the left most tensor is 1 (i.e. a dummy index) on its' left most leg\n",
    "\n",
    "    for k in 1:N-1\n",
    "        #print(size(psi),\"     \");\n",
    "\n",
    "        U, S, V = svd(psi); # Perform an SVD of the state matrix\n",
    "\n",
    "        mps_temp = reshape(U,(left_bond_dim,d,size(S,1))); # The matrix U (which is on the left of SVD) is reshaped into the tensor at site k\n",
    "\n",
    "        push!(mps_state, mps_temp); # Store it into the MPS\n",
    "\n",
    "        left_bond_dim = size(S,1); # This is the left bond dimension for the next tensor\n",
    "\n",
    "        psi_1 = Diagonal(S)*V'; # This is the matrix for the remaining part of the original vector\n",
    "\n",
    "        #print(size(psi_1),\"     \");\n",
    "        if k == N-1 # This is the step that constructs the tensor at the right end of the MPS\n",
    "            mps_temp = reshape(psi_1, left_bond_dim[1],d,1);\n",
    "            push!(mps_state,mps_temp)\n",
    "        else\n",
    "             # This is the step where the the remaining part vector is appropriately reshaped.\n",
    "             # For this, note that we reshape the remaining part as ((dimensions of S) * d) x ((size at previous step)/d)\n",
    "             # This ensures that the effective flip which happens at the middle of the spectrum due to thin SVD is adjusted for.  \n",
    "            \n",
    "            right_size = cld(size(psi,2),d);\n",
    "            \n",
    "            psi = reshape(psi_1,size(S,1)*d,right_size);\n",
    "\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    return mps_state\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MPS to State\n",
    "\n",
    "$\\quad$ Given the MPS $\\{A_1, A_2, A_3,\\dots,A_N\\}$, we can determine the state as follows\n",
    "\n",
    "$\\quad$ $\\Psi_{\\sigma_1,\\sigma_2,\\sigma_3,\\dots,\\sigma_N} = \\sum_{\\{a\\}}A^{\\sigma_1}_{1; a_1, a_2} A^{\\sigma_2}_{2; a_2, a_3} \\dots A^{\\sigma_N}_{N; a_{N-1} a_{N}}$. Recall that $a_1$ and $a_N$ are trivial (dummy) indices of dimension $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mps_to_state (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A function to perform the summation given above to obtain the state vector from the MPS.\n",
    "    The first step is to convert it to the tensor ψ_{σ₁,σ₂,…}, which is then reshaped to a dᴺ dimensional Vector\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function mps_to_state(mps_state;return_tensor = false)\n",
    "\n",
    "    mps_temp = mps_state; #using the left-bottom-right counting\n",
    "\n",
    "    N = length(mps_temp);\n",
    "\n",
    "    d = size(mps_temp[1])[2];\n",
    "\n",
    "    state_tensor_size = ntuple(_ -> d, N);\n",
    "\n",
    "    state_tensor  = fill(0.0,state_tensor_size...);\n",
    "\n",
    "    G = CartesianIndices(state_tensor);\n",
    "\n",
    "    @threads for g in G\n",
    "\n",
    "        A = mps_temp[1][:,g[1],:];\n",
    "\n",
    "        for l in 2:N\n",
    "            \n",
    "            f = g[l];\n",
    "\n",
    "            B = mps_temp[l][:,f,:];\n",
    "\n",
    "            @einsum M[i,j] := A[i,m]*B[m,j];\n",
    "\n",
    "            A = M\n",
    "        \n",
    "        end\n",
    "        \n",
    "        state_tensor[g] = A[1]\n",
    "    end\n",
    "\n",
    "    if return_tensor\n",
    "\n",
    "        return_obj = state_tensor;\n",
    "    \n",
    "    else\n",
    "        \n",
    "        return_obj = reshape(state_tensor,d^N);\n",
    "\n",
    "    end\n",
    "    return return_obj\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.894295549061714e-14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "    A quick test to check : We generate a state, then generate the MPS from it and try to retrieve back the original state.\n",
    "    Then do we get the correct state back?\n",
    "\n",
    "\"\"\"\n",
    "N = 8;\n",
    "d = 2;\n",
    "D = 10;\n",
    "\n",
    "state_vec = rand(d^N); # The initial random state\n",
    "\n",
    "mps_vec = state_to_mps(state_vec, N); # Convert that to MPS\n",
    "\n",
    "state_vec_2 = mps_to_state(mps_vec); # Re-convert the MPS back to a state \n",
    "\n",
    "norm(state_vec .- state_vec_2) # Compute the error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Product Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ Here we discuss the Matrix Product Operators that encode matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The general idea is the following\n",
    "\n",
    "$\\quad$ A matrix (say, Hamiltonian) can be expanded in terms of the basis states of local Hilbert spaces\n",
    "\n",
    "$\\quad$ $H = \\sum_{\\sigma, \\tau} c^{\\sigma, \\tau}\\ket{\\tau}\\bra{\\sigma}$\n",
    "\n",
    "$\\quad$ $\\;\\;\\;\\; = \\sum_{\\sigma_1, \\tau_1} \\dots \\sum_{\\sigma_L , \\tau_L} c^{\\sigma_1,\\sigma_2,\\dots,\\sigma_L}_{\\tau_1, \\tau_2,\\dots, \\tau_L} \\ket{\\tau_1, \\tau_2,\\dots, \\tau_L}\\bra{\\sigma_1,\\sigma_2,\\dots,\\sigma_L}$\n",
    "\n",
    "$\\quad$ The coefficients $c$ can be decomposed in terms of Matrix Products. For each site $i$ and every pair $\\{ \\ket{\\tau_i}\\bra{\\sigma_i}\\}$, we introduce a set of matrices $(W^{\\sigma_i, \\tau_i}_{i})_{w_{i-1},w_{i}}$.\n",
    "\n",
    "$\\quad$ These matrices then satisfy the property:\n",
    "\n",
    "$\\quad$ $\\sum_{\\mathbf{w}} (W^{\\sigma_1 \\tau_1}_1)_{w_0, w_1} (W^{\\sigma_2 \\tau_2}_2)_{w_1, w_2} \\cdots (W^{\\sigma_L \\tau_L}_{L})_{w_{L-1}, w_L} = c^{\\sigma_1,\\sigma_2,\\dots,\\sigma_L}_{\\tau_1, \\tau_2,\\dots, \\tau_L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The general rule of thumb is that the Hamiltonians of the form $H = \\sum_i X_i$ can be represented with $4-$ tensors of the form\n",
    "\n",
    "$\\quad$ $H_{i} = \\begin{pmatrix} I & 0 \\\\ X & I \\end{pmatrix}$\n",
    "\n",
    "$\\quad$ Similarly, the a nearest-neighbour Hamiltonian of the form $H = \\sum_i X_i Y_{i + 1}$ should have the following $4-$ tensors\n",
    "\n",
    "$\\quad$ $H_{i} = \\begin{pmatrix} I & 0 & 0 \\\\ X & 0 & 0 \\\\ 0 & Y & I \\end{pmatrix}$\n",
    "\n",
    "$\\quad$ Now, on the other hand, if we have both nearest neighbour and local terms, i.e. $H = \\sum_{i} X_{i}Y_{i + 1} + g Z_{i}$, then the local tensor is\n",
    "\n",
    "$\\quad$ $H_{i} = \\begin{pmatrix} I & 0 & 0 \\\\ X & 0 & 0 \\\\ g Z & Y & I \\end{pmatrix}$\n",
    "\n",
    "$\\quad$ The idea is similar for other Hamiltonians, but there are usually many more subtleties. For now, we work on a case by case basis.\n",
    "\n",
    "$\\quad$ The quantum Heisenberg chain, given by $H = J\\sum_{i}\\vec{\\sigma}_{i}\\vec{\\sigma}_{i + 1} + h \\sum_{i}\\sigma^{z}_{i}$.\n",
    "\n",
    "$\\quad$ The constituent $4-$ tensor is given by:\n",
    "\n",
    "$\\quad$ $H_{i} = \\begin{pmatrix} I & 0 & 0 & 0 & 0 \\\\ \\sigma^{z} & 0 & 0 & 0 & 0 \\\\ \\sigma^{+} & 0 & 0 & 0 & 0 \\\\ \\sigma^{-} & 0 & 0 & 0 & 0  \\\\ h\\sigma^{z} & J\\sigma^{z} & \\frac{J}{2}\\sigma^{+} & \\frac{J}{2}\\sigma^{-} & I \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heisenberg_MPO (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function Heisenberg_MPO(J,h,N)\n",
    "\n",
    "    σᶻ = [1 0 0; 0 0 0; 0 0 -1];\n",
    "\n",
    "    σ⁺ = [0 sqrt(2) 0; 0 0 sqrt(2); 0 0 0];\n",
    "\n",
    "    σ⁻ = [0 0 0; sqrt(2) 0 1; 0 sqrt(2) 1];\n",
    "\n",
    "    I2 = I + zeros(3,3);\n",
    "\n",
    "    Hi = fill(0.0,(5,3,5,3));\n",
    "\n",
    "    Hi[1,:,1,:] = I2;\n",
    "\n",
    "    Hi[2,:,1,:] = σᶻ;\n",
    "\n",
    "    Hi[3,:,1,:] = σ⁺;\n",
    "\n",
    "    Hi[4,:,1,:] = σ⁻;\n",
    "\n",
    "    Hi[5,:,1,:] = -h * σᶻ;\n",
    "\n",
    "    Hi[5,:,2,:] = J*σᶻ;\n",
    "\n",
    "    Hi[5,:,3,:] = (J/2)*σ⁺;\n",
    "\n",
    "    Hi[5,:,4,:] = (J/2)*σ⁻;\n",
    "\n",
    "    Hi[5,:,5,:] = I2;\n",
    "\n",
    "    Htensor = Any[];\n",
    "\n",
    "    H = [Hi for i in 1:N];\n",
    "\n",
    "    H[1] = Hi[size(Hi)[1]:size(Hi)[1],:,:,:];\n",
    "    H[N] = Hi[:,:,1:1,:];\n",
    "    \n",
    "    return H \n",
    "\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPO_to_Ham (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "    Function to convert an MPO to a Hamitlonian matrix.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function MPO_to_Ham(mpo_operator)\n",
    "\n",
    "    H_MPO = mpo_operator;\n",
    "\n",
    "    N = length(H_MPO)\n",
    "\n",
    "    T_res = H_MPO[1][1,:,:,:];\n",
    "\n",
    "    for p in 2:N\n",
    "\n",
    "        B = H_MPO[p];\n",
    "\n",
    "        @einsum M1[i,j,k,l,m] := T_res[i,μ,j]*B[μ,k,l,m]\n",
    "\n",
    "        M1 = permutedims(M1,(1,3,4,2,5));\n",
    "\n",
    "        L = size(M1);\n",
    "\n",
    "        M1 = reshape(M1,(L[1]*L[2],L[3],L[4]*L[5]));\n",
    "\n",
    "        T_res = M1;\n",
    "\n",
    "    end\n",
    "\n",
    "    return T_res[:,1,:]\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4;\n",
    "J = 1.;\n",
    "h = 1.;\n",
    "\n",
    "Heis_MPO = Heisenberg_MPO(J,h,N);\n",
    "\n",
    "Heis_MAT = MPO_to_Ham(Heis_MPO);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closing the Zipper : Expectation value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ Here we discuss the method to ``close the zipper'' in order to compute the expectation values of the form $\\bra{\\phi} \\hat{O} \\ket{\\psi}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The closing the zipper mechanism follows practically as the contratction of the result of the previous contraction $C_{n-1}$ (rank $-3$), with\n",
    "\n",
    "$\\quad$ the MPS tensor at that index $B_n$ and the dual MPS tensor $A_n$ (like the zipper for states, both rank $-3$), with the additional $\\textit{operator}$ MPO tensor\n",
    "\n",
    "$\\quad$ inserted at that position, which we denote by $O_n$ (rank $-4$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ The fist contraction step is to contract $B_n$ (which is below $O_n$), with $C_{n - 1}$. \n",
    "\n",
    "$\\quad$ This consumes the left index of $B_n$ and the bottom index of $C_{n - 1}$. Both indices have the bond dimension $D$. \n",
    "\n",
    "$\\quad$ The result is some tensor $M_1$ (repalcing $C_{n-1}$), which is a rank $-4$ tensor. \n",
    "\n",
    "$\\quad$ $M_1$ has its' top leg connecting to the left leg of $A_n$, it's right leg connects to the left leg of $O_n$. \n",
    "\n",
    "$\\quad$ The bottom index of $M_1$ connects to the bottom index of $O_n$, while it gets a free left index (which was the free right index of $B_n$).\n",
    "\n",
    "$\\quad$ The next step is to contract $M_1$ with $O_n$. This is a contraction of $2$ indices, i.e. the bottom and left indices of $O_n$ with the corresponding index of $M_1$.\n",
    "\n",
    "$\\quad$ $\\textit{to be continued \\dots}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rand_MPO (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Function to generate a random MPO \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function rand_MPO(N,d,D; d1 = Normal(0,1))\n",
    "\n",
    "    I2 = I  + zeros(d,d);\n",
    "\n",
    "    H_MPO = Any[];\n",
    "\n",
    "    HL = fill(0.0,(D,d,D,d));\n",
    "\n",
    "    for l in 1:N \n",
    "\n",
    "        HL[1,:,1,:] = I2;\n",
    "\n",
    "        for j in 2:(D-1)\n",
    "\n",
    "            HL[j,:,1,:] = rand(d1,(d,d));\n",
    "            HL[D,:,j,:] = rand(d1,(d,d));\n",
    "\n",
    "        end \n",
    "\n",
    "        HL[D,:,D,:] = I2; \n",
    "\n",
    "        push!(H_MPO,HL)\n",
    "\n",
    "    end \n",
    "\n",
    "    H_MPO[1] = H_MPO[1][size(HL,1):size(HL,1),:,:,:];\n",
    "\n",
    "    H_MPO[N] = H_MPO[N][:,:,1:1,:];\n",
    "\n",
    "    return H_MPO \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity_MPO (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "    MPO representation of an Identity matrix\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function Identity_MPO(N,d)\n",
    "\n",
    "    I2 = I  + zeros(d,d);\n",
    "\n",
    "    H_MPO = Any[];\n",
    "    \n",
    "    D = 2;\n",
    "\n",
    "    HL = fill(0.0,(D,d,D,d));\n",
    "\n",
    "    for l in 1:N \n",
    "\n",
    "        for j in 1:D\n",
    "\n",
    "            HL[j,:,1,:] = I2;\n",
    "            HL[D,:,j,:] = I2;\n",
    "\n",
    "        end \n",
    "\n",
    "        HL[D,:,1,:] = I2/N;\n",
    "        \n",
    "        push!(H_MPO,HL)\n",
    "\n",
    "    end \n",
    "\n",
    "    H_MPO[1] = H_MPO[1][size(HL,1):size(HL,1),:,:,:];\n",
    "\n",
    "    H_MPO[N] = H_MPO[N][:,:,1:1,:];\n",
    "\n",
    "    return H_MPO \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP_right (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function ZIP_right(Cn_minus_1, An, Bn, On)\n",
    "    \n",
    "    # We count the legs from left to right. Thus, the first index of Cn_minus_1 must have bond dimension same as An, and the second index should\n",
    "    # have bond dimension same as Bn\n",
    "\n",
    "    Cn1 = Cn_minus_1;\n",
    "\n",
    "    @einsum M1[i,j,l,m] := An[i,j,k]*Cn1[k,l,m]\n",
    "\n",
    "    @einsum M2[i,l,m,n] := M1[i,j,k,l]*On[m,n,k,j]\n",
    "\n",
    "    @einsum M3[i,j,k] := M2[i,m,j,n]*Bn[m,n,k]\n",
    "\n",
    "    return M3\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP_left (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function ZIP_left(Cn_minus_1, An, Bn, On)\n",
    "    \n",
    "    # We count the legs from left to right. Thus, the first index of Cn_minus_1 must have bond dimension same as An, and the second index should\n",
    "    # have bond dimension same as Bn\n",
    "\n",
    "    Cn1 = Cn_minus_1;\n",
    "\n",
    "    @einsum M1[i,j,l,m] := Bn[i,j,k]*Cn1[k,l,m]\n",
    "\n",
    "    @einsum M2[i,l,m,n] := M1[i,j,k,l]*On[k,j,m,n]\n",
    "\n",
    "    @einsum M3[i,j,k] := M2[i,m,j,n]*An[m,n,k]\n",
    "\n",
    "    return M3\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp_val_left (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Here we define a function to compute the expectation value by the left zipper method, given the MPS and MPO.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function exp_val_left(mps_state_1, mps_state_2, mpo_operator)\n",
    "\n",
    "    N = length(mps_state_1);\n",
    "\n",
    "    T_res = fill(1.0,(1,1,1));\n",
    "\n",
    "    for l in 1:N \n",
    "\n",
    "        b_state = permutedims(conj.(mps_state_2[l]),(3,2,1));\n",
    "\n",
    "        a_state = mps_state_1[l];\n",
    "\n",
    "        op_tensor = mpo_operator[l];\n",
    "\n",
    "        T_res = ZIP_left(T_res,a_state,b_state,op_tensor);\n",
    "\n",
    "    end \n",
    "\n",
    "    return T_res[1,1,1]\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04113929392532821"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Here we test if this ``expectation value'' calculation gives us a proper number.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "N = 10;\n",
    "d = 3;\n",
    "D1 = 20;\n",
    "D2 = 10;\n",
    "D3 = 5;\n",
    "\n",
    "V_state = mixed_canonical(rand_MPS(N,d,D1));\n",
    "\n",
    "V_state_dag = mixed_canonical(rand_MPS(N,d,D2));\n",
    "\n",
    "O_operator = rand_MPO(N,d,D3);\n",
    "\n",
    "C = exp_val_left(V_state, V_state_dag, O_operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ Here we implement the action of an MPO on an MPS.\n",
    "\n",
    "$\\quad$ For this, we use the ``zip-up'' algorithm, which proceeds as follows.\n",
    "\n",
    "$\\quad$ 1.) The bottom index of the first MPO $O_1$ tensor is contracted with the top index of the first MPS tensor $A_1$. This gives us a rank $-3$ tensor $C_1$, with its' left leg $s_1$ being the  $\\quad \\quad \\;$ top index of $O_1$ and the two right indices (which connect to the left indices of $O_2$ and $A_2$) are given by the two left indices of $O_1$ (denoted by $\\mu_1) and $A_1$ (denoted  $\\quad \\quad \\;$ by $\\alpha_1$) respectively.\n",
    "\n",
    "$\\quad$ 2.) From $C_1$, we can perform an SVD. To do that we reshape $(\\mu_1,\\alpha_1)$ into one index and perform SVD. From this, we extract $U_1$ and $S_1 V_1^\\dagger$. \n",
    "\n",
    "$\\quad$ 3.) Then $U_1$ is treated as the resulting tensor of the MPS due to this contraction. And $S_1 V^\\dagger_1$ is the next tensor to be contracted with $A_2$ and $O_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP_up (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Function to perform one step of the zip-up algorithm\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function ZIP_up(Rn_minus_1, An, On)\n",
    "\n",
    "    Rn = Rn_minus_1 ; # This is the resulting SV⁺ from the previous step. This is a 3-tensor.\n",
    "\n",
    "    @einsum M1[i,j,k,l,m] := On[i,j,k,n]*An[l,n,m]\n",
    "\n",
    "    M1 = permutedims(M1,(4,1,2,3,5));\n",
    "\n",
    "    @einsum C[i,j,k,l] := Rn[i,a,b]*M1[b,a,j,k,l];\n",
    "\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10;\n",
    "d = 2;\n",
    "Rn_minus_1 = rand(Normal(0,1),(D,D,D));\n",
    "An = rand(Normal(0,1),(D,d,D));\n",
    "On = rand(Normal(0,1),(D,d,D,d));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPO_on_MPS (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Here we write the function that computes the action of an MPO on an MPS\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "function MPO_on_MPS(mpo_operator, mps_state)\n",
    "\n",
    "    H_MPO = mpo_operator;\n",
    "\n",
    "    A_MPS = mps_state;\n",
    "\n",
    "    N = length(H_MPO);\n",
    "\n",
    "    Rn = fill(1.0,(1,1,1));\n",
    "\n",
    "    Res_MPS = Any[];\n",
    "\n",
    "    for l in 1:N \n",
    "\n",
    "        An = A_MPS[l];\n",
    "\n",
    "        On = H_MPO[l];\n",
    "\n",
    "        C = ZIP_up(Rn, An, On);\n",
    "\n",
    "        L = size(C);\n",
    "\n",
    "        Cdim = reshape(C,(L[1]*L[2],L[3]*L[4]));\n",
    "\n",
    "        U, S, V = svd(Cdim,full=false);\n",
    "\n",
    "        push!(Res_MPS,reshape(U,(L[1],L[2],size(U)[2])));\n",
    "\n",
    "        Sdiag = Diagonal(S)*V';\n",
    "\n",
    "        Rn = reshape(Sdiag,(size(Sdiag)[1],L[3],L[4]));\n",
    "\n",
    "    end\n",
    "\n",
    "    return Res_MPS\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10;\n",
    "D1 = 20;\n",
    "D2 = 5;\n",
    "d = 2;\n",
    "R_MPS = rand_MPS(N,d,D1);\n",
    "R_MPO = rand_MPO(N,d,D2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = MPO_on_MPS(R_MPO,R_MPS); # This gives the MPS obtained by the action of the MPO on the input MPS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## DMRG using MPO and MPS : $\\textcolor{red}{Work\\;\\;In\\;\\;Progress}$\n",
    "$\\quad$ In this section, we discuss the one-site-update approach to DMRG using MPO and MPS.\n",
    "\n",
    "$\\quad$ The basic idea is to start with a random MPS $\\ket{\\psi}$, and find the expectation value $\\bra{\\psi}\\hat{O}\\ket{\\psi}$. \n",
    "\n",
    "$\\quad$ This expectation value is extremized with respect to the components of $\\ket{\\psi}$ to target some eigenvalue $\\lambda$ via extremization of $\\bra{\\psi}\\hat{O}\\ket{\\psi} - \\lambda \\braket{\\psi \\vert\\psi}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMRG_1site (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Here we write the 1-site update approach for DMRG to determine the ground state of a Hamiltonian\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function DMRG_1site(Ham_MPO,Max_Bond_Dim,Num_Sweeps)\n",
    "\n",
    "    N = length(Ham_MPO);\n",
    "\n",
    "    H = Ham_MPO;\n",
    "\n",
    "    D = Max_Bond_Dim;\n",
    "\n",
    "    NS = Num_Sweeps;\n",
    "\n",
    "    # The first step is to generate tha random | ψ >\n",
    "\n",
    "    d = size(H[1])[4]; # We assume that the physical dimensions are the same always. This can be generalized easily.\n",
    "\n",
    "    ψ = mixed_canonical(rand_MPS(N,d,D)); # We ensure that the state | ψ > is cast into the mixed canonical (normalized) form.\n",
    "\n",
    "    # For the 1-site update procedure, we fix a site l and contract from the left and right of l. The resulting matrix to be diagonalized to find the minimum energy.\n",
    "\n",
    "    # The step now is to contract < ψ | H | ψ > from the left upto the index l, and then from the right. The results for each contraction are stored in the MPS CZ.\n",
    "\n",
    "    # To begin, we cast CZ into a right canonical form\n",
    "\n",
    "    CZ = [fill(1.0,(1,1,1)) for i in 1:N+1];\n",
    "\n",
    "    for l in N:-1:1\n",
    "\n",
    "        ψn = permutedims(conj.(ψ[l]),(3,2,1));\n",
    "\n",
    "        CZ[l] = ZIP_right(CZ[l+1],ψ[l],ψn,H[l])\n",
    "\n",
    "    end\n",
    "\n",
    "    EV_list = Any[]; #This is the eigenvalue that we will store at each sweep.\n",
    "    \n",
    "    for J in 1:NS \n",
    "\n",
    "        ## First we do a right sweep.\n",
    "\n",
    "        for l in 1:N \n",
    "\n",
    "            HM = H[l];\n",
    "\n",
    "            CM = CZ[l];\n",
    "            \n",
    "            CM2 = CZ[l+1];\n",
    "\n",
    "            @einsum M1[i,k,l,m,n] := CM[i,j,k]*HM[j,l,m,n]\n",
    "\n",
    "            @einsum M2[i,j,k,m,n,p] := M1[i,j,k,l,m]*CM2[n,l,p];\n",
    "\n",
    "            M2 = permutedims(M2,(1,3,6,2,4,5));\n",
    "\n",
    "            L = size(M2);\n",
    "\n",
    "            H = sparse(reshape(M2,(L[1]*L[2]*L[3],L[4]*L[5]*L[6])));\n",
    "\n",
    "            #V = ψ[l];\n",
    "\n",
    "            val, vecs = Arpack.eigs(H;nev=1,which=:SM); # Use ARPACK to obtain the eigenvalue and eigenvector\n",
    "\n",
    "            push!(EV_list,val); # The eigenvalue stored from this iteration.\n",
    "\n",
    "            M3 = reshape(vecs[:,1],(size(M2)[1]*size(M2)[2],size(M2)[3]));\n",
    "\n",
    "            U, S, V = svd(M3,full=false);\n",
    "\n",
    "            ψ[l] = reshape(U,(size(M2)[1],size(M2)[2],size(U)[2]));\n",
    "\n",
    "            if l < N \n",
    "                G = ψ[l + 1];\n",
    "                T = Diagonal(S)*V';\n",
    "                @einsum V[i,j,k] = T[i,m]*G[m,j,k];\n",
    "                ψ[l + 1] = V;\n",
    "            end\n",
    "\n",
    "            CZ[l + 1] = ZIP_left(CZ[l],ψ[l],permutedims(conj.(ψ[l]),(3,2,1)),H[l]);\n",
    "        \n",
    "        end\n",
    "\n",
    "        ## Now we do a left sweep\n",
    "\n",
    "        for l in N:-1:1 \n",
    "\n",
    "            HM = H[l];\n",
    "\n",
    "            CM = CZ[l];\n",
    "            \n",
    "            CM2 = CZ[l+1];\n",
    "\n",
    "            @einsum M1[i,k,l,m,n] := CM[i,j,k]*HM[j,l,m,n]\n",
    "\n",
    "            @einsum M2[i,j,k,m,n,p] := M1[i,j,k,l,m]*CM2[n,l,p];\n",
    "\n",
    "            M2 = permutedims(M2,(1,3,6,2,4,5));\n",
    "\n",
    "            L = size(M2);\n",
    "\n",
    "            H = sparse(reshape(M2,(L[1]*L[2]*L[3],L[4]*L[5]*L[6])));\n",
    "\n",
    "            #V = ψ[l];\n",
    "\n",
    "            val, vecs = Arpack.eigs(H;nev=1,which=:SM); # Use ARPACK to obtain the eigenvalue and eigenvector\n",
    "\n",
    "            push!(EV_list,val); # The eigenvalue stored from this iteration.\n",
    "\n",
    "            M3 = reshape(vecs[:,1],(size(M2)[1]*size(M2)[2],size(M2)[3]));\n",
    "\n",
    "            U, S, V = svd(M3,full=false);\n",
    "\n",
    "            ψ[l] = reshape(U,(size(M2)[1],size(M2)[2],size(U)[2]));\n",
    "\n",
    "            if l > 1 \n",
    "                G = ψ[l - 1];\n",
    "                T = Diagonal(S)*V';\n",
    "                @einsum V[i,j,k] = T[i,m]*G[m,j,k];\n",
    "                ψ[l - 1] = V;\n",
    "            end\n",
    "\n",
    "            CZ[l + 1] = ZIP_right(CZ[l+2],ψ[l],permutedims(conj.(ψ[l]),(3,2,1)),H[l]);\n",
    "        \n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    return EV_list, ψ\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XY_MPO"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Function that creates the MPO Hamiltonian for an XY chain with N spins and open boundary conditions.\n",
    "\"\"\"\n",
    "function XY_MPO(N)\n",
    "    σp = zeros((2,2))\n",
    "    σp[1,2] = 1\n",
    "    σm = zeros((2,2))\n",
    "    σm[2,1] = 1\n",
    "    ## I_l\n",
    "    I2 = I  + zeros(2,2)\n",
    "\n",
    "    #Construct the MPO tensor\n",
    "    Hl = zeros((4,2,4,2))\n",
    "    Hl[1,:,1,:] = I2\n",
    "    Hl[2,:,1,:] = σm\n",
    "    Hl[3,:,1,:] = σp\n",
    "    Hl[4,:,2,:] = -0.5*σp\n",
    "    Hl[4,:,3,:] = -0.5*σm\n",
    "    Hl[4,:,4,:] = I2\n",
    "    ## H\n",
    "    H = [Hl for l in 1:N]\n",
    "    H[1] = Hl[size(Hl)[1]:size(Hl)[1],:,:,:]\n",
    "    H[N] = Hl[:,:,1:1,:]\n",
    "    \n",
    "    return H\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "AssertionError: size(M1, 3) == size(On, 1)",
     "output_type": "error",
     "traceback": [
      "AssertionError: size(M1, 3) == size(On, 1)\n",
      "\n",
      "Stacktrace:\n",
      " [1] macro expansion\n",
      "   @ ~/.julia/packages/Einsum/AVMOj/src/Einsum.jl:209 [inlined]\n",
      " [2] ZIP_left(Cn_minus_1::Array{Float64, 3}, An::Array{Float64, 3}, Bn::Array{Float64, 3}, On::Array{Float64, 4})\n",
      "   @ Main ~/Dropbox/AKLTandTopologyStuff/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X65sZmlsZQ==.jl:10\n",
      " [3] top-level scope\n",
      "   @ ~/Dropbox/AKLTandTopologyStuff/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y113sZmlsZQ==.jl:12"
     ]
    }
   ],
   "source": [
    "N = 10;\n",
    "D = 5;\n",
    "d = 2;\n",
    "CZ = [fill(1.0,(1,1,1)) for i in 1:N+1];\n",
    "ψ = mixed_canonical(rand_MPS(N,d,D));\n",
    "H = rand_MPO(N,d,D);\n",
    "\n",
    "for l in N:-1:1\n",
    "\n",
    "    ψn = permutedims(conj.(ψ[l]),(3,2,1));\n",
    "\n",
    "    CZ[l] = ZIP_left(CZ[l+1],ψn,ψ[l],H[l])\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ψ = mixed_canonical(rand_MPS(N,d,D));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "AssertionError: size(M1, 2) == size(On, 2)",
     "output_type": "error",
     "traceback": [
      "AssertionError: size(M1, 2) == size(On, 2)\n",
      "\n",
      "Stacktrace:\n",
      " [1] macro expansion\n",
      "   @ ~/.julia/packages/Einsum/AVMOj/src/Einsum.jl:209 [inlined]\n",
      " [2] ZIP_left(Cn_minus_1::Array{Float64, 3}, An::Array{ComplexF64, 3}, Bn::Array{ComplexF64, 3}, On::Float64)\n",
      "   @ Main ~/Dropbox/AKLTandTopologyStuff/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X65sZmlsZQ==.jl:10\n",
      " [3] DMRG_1site(Ham_MPO::Vector{Array{Float64, 4}}, Max_Bond_Dim::Int64, Num_Sweeps::Int64)\n",
      "   @ Main ~/Dropbox/AKLTandTopologyStuff/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y112sZmlsZQ==.jl:81\n",
      " [4] top-level scope\n",
      "   @ ~/Dropbox/AKLTandTopologyStuff/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y131sZmlsZQ==.jl:10"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "N = 20\n",
    "D = 10 #bond dimension for DMRG\n",
    "Nsweeps = 3 #nr of sweeps\n",
    "\n",
    "# Hamiltonian MPO\n",
    "H = XY_MPO(N)\n",
    "\n",
    "# DMRG\n",
    "E_list,M = DMRG_1site(H,D,Nsweeps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
